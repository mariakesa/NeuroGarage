{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 768])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "class ContrastiveDataset(Dataset):\n",
    "    def __init__(self, n=10000, num_groups=10):\n",
    "        self.n = n\n",
    "        self.num_groups = num_groups\n",
    "        self.range_size = self.n // self.num_groups\n",
    "        self.ranges = [\n",
    "            (self.range_size * i, self.range_size * (i + 1)) for i in range(self.num_groups)\n",
    "        ]\n",
    "\n",
    "        # Handle any remaining samples by adding them to the last range\n",
    "        if self.range_size * self.num_groups < self.n:\n",
    "            self.ranges[-1] = (self.ranges[-1][0], self.n)\n",
    "\n",
    "        # Assign group labels to each index for visualization\n",
    "        self.labels = torch.zeros(self.n, dtype=torch.long)\n",
    "        for i in range(self.num_groups):\n",
    "            start, end = self.ranges[i]\n",
    "            self.labels[start:end] = i\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor = idx\n",
    "\n",
    "        range_idx = anchor // self.range_size\n",
    "        if range_idx >= self.num_groups:\n",
    "            range_idx = self.num_groups - 1  # Correct adjustment\n",
    "\n",
    "        start, end = self.ranges[range_idx]\n",
    "        positive_sample = torch.randint(start, end, (1,)).item()\n",
    "\n",
    "        return torch.tensor(anchor, dtype=torch.long), torch.tensor(positive_sample, dtype=torch.long)\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(n, 768)\n",
    "        self.fc = torch.nn.Linear(768, 768)\n",
    "        self.non_linearity = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        out = self.fc(emb)\n",
    "        out = self.non_linearity(out)\n",
    "        return out\n",
    "\n",
    "# Number of unique items in the dataset\n",
    "n = 10000\n",
    "\n",
    "# Initialize the query encoder (encoder_q)\n",
    "encoder_q = Encoder(n)\n",
    "encoder_k = Encoder(n)\n",
    "\n",
    "# Copy the parameters from encoder_q to encoder_k\n",
    "encoder_k.load_state_dict(encoder_q.state_dict())\n",
    "\n",
    "# Create an instance of your dataset\n",
    "dataset = ContrastiveDataset(n=10000, num_groups=10)\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 25\n",
    "\n",
    "# Create a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# Total number of samples in the dataset\n",
    "n = len(dataset)\n",
    "\n",
    "# Number of keys to sample for the queue\n",
    "queue_size = 1000\n",
    "\n",
    "# Randomly sample 1000 indices from the dataset\n",
    "key_indices = random.sample(range(n), queue_size)\n",
    "\n",
    "# Convert to a tensor\n",
    "key_indices = torch.tensor(key_indices, dtype=torch.long)\n",
    "\n",
    "# Ensure the key encoder is on the correct device (e.g., CPU or GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "encoder_k.to(device)\n",
    "key_indices = key_indices.to(device)\n",
    "\n",
    "# Set the key encoder to evaluation mode\n",
    "encoder_k.eval()\n",
    "\n",
    "# Disable gradient computation for the key encoder\n",
    "with torch.no_grad():\n",
    "    # Obtain key embeddings\n",
    "    key_embeddings = encoder_k(key_indices)\n",
    "print(key_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchors shape: torch.Size([25])\n",
      "Positives shape: torch.Size([25])\n"
     ]
    }
   ],
   "source": [
    "#Single loop state\n",
    "# Get one batch from the dataloader\n",
    "batch = next(iter(dataloader))\n",
    "\n",
    "# Unpack the batch into anchors and positives\n",
    "anchors, positives = batch\n",
    "\n",
    "# Print the shapes of the anchors and positives tensors\n",
    "print('Anchors shape:', anchors.shape)\n",
    "print('Positives shape:', positives.shape)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
